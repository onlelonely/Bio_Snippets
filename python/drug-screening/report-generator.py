# ---------------------------------------------
# Source: Drug Screening Pipeline (CPV)
# ---------------------------------------------

"""
ç”Ÿæˆç¶œåˆåˆ†æå ±å‘Š
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import json
import logging
from datetime import datetime
import numpy as np

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ReportGenerator:
    def __init__(self):
        self.report_dir = Path("analysis/reports")
        self.report_dir.mkdir(parents=True, exist_ok=True)
        
    def generate_markdown_report(self):
        """ç”Ÿæˆ Markdown æ ¼å¼çš„ç¶œåˆå ±å‘Š"""
        logger.info("ğŸ“ ç”Ÿæˆ Markdown å ±å‘Š")
        
        report_content = f"""# CPV è™›æ“¬ç¯©é¸åˆ†æå ±å‘Š

## å ±å‘Šä¿¡æ¯
- **ç”Ÿæˆæ™‚é–“**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **é …ç›®**: Canine Parvovirus æŠ—ç—…æ¯’è—¥ç‰©è™›æ“¬ç¯©é¸
- **ç›®æ¨™**: VP2-TfR çµåˆç•Œé¢æŠ‘åˆ¶åŠ‘

## åŸ·è¡Œæ‘˜è¦

"""
        
        # è¼‰å…¥çµ±è¨ˆä¿¡æ¯
        try:
            stats_file = Path("analysis/binding_affinity/binding_affinity_statistics.json")
            if stats_file.exists():
                with open(stats_file, 'r') as f:
                    stats = json.load(f)
                
                report_content += f"""### å°æ¥çµ±è¨ˆ
- **ç¸½åŒ–åˆç‰©æ•¸**: {stats.get('total_compounds', 'N/A'):,}
- **å¹³å‡çµåˆèƒ½**: {stats.get('mean_binding_affinity', 'N/A'):.2f} kcal/mol
- **æœ€ä½³çµåˆèƒ½**: {stats.get('min_binding_affinity', 'N/A'):.2f} kcal/mol
- **å¼·çµåˆè€…æ•¸é‡**: {stats.get('strong_binders', 'N/A')} ({stats.get('strong_binder_rate', 0)*100:.1f}%)

"""
        except Exception as e:
            logger.warning(f"âš ï¸ ç„¡æ³•è¼‰å…¥çµ±è¨ˆä¿¡æ¯: {e}")
        
        # è¼‰å…¥é™½æ€§å°ç…§ä¿¡æ¯
        try:
            controls_file = Path("analysis/binding_affinity/positive_control_rankings.json")
            if controls_file.exists():
                with open(controls_file, 'r') as f:
                    controls = json.load(f)
                
                report_content += "### é™½æ€§å°ç…§çµæœ\n"
                for name, data in controls.items():
                    report_content += f"- **{name.title()}**: æ’å {data['rank']} ({data['percentile']:.1f}%), çµåˆèƒ½ {data['binding_affinity']:.2f} kcal/mol\n"
                report_content += "\n"
        except Exception as e:
            logger.warning(f"âš ï¸ ç„¡æ³•è¼‰å…¥å°ç…§ä¿¡æ¯: {e}")
        
        # è¼‰å…¥ç¯©é¸æ‘˜è¦
        try:
            filter_file = Path("analysis/sar/filtering_summary.json")
            if filter_file.exists():
                with open(filter_file, 'r') as f:
                    filter_summary = json.load(f)
                
                report_content += f"""### ç¯©é¸çµæœ
- **åŸå§‹çµæœæ•¸**: {filter_summary.get('original_results', 'N/A'):,}
- **æœ€çµ‚ç¯©é¸æ•¸**: {filter_summary.get('final_filtered', 'N/A'):,}
- **ç¯©é¸æˆåŠŸç‡**: {filter_summary.get('success_rate', 0)*100:.2f}%

### ç¯©é¸æ­¥é©Ÿ
"""
                for i, step in enumerate(filter_summary.get('filtering_steps', []), 1):
                    report_content += f"{i}. {step}\n"
                report_content += "\n"
        except Exception as e:
            logger.warning(f"âš ï¸ ç„¡æ³•è¼‰å…¥ç¯©é¸æ‘˜è¦: {e}")
        
        # æ·»åŠ å‰ 10 å€‹å€™é¸åˆ†å­
        try:
            top_file = Path("analysis/sar/final_selection_essential_top_20.csv")
            if top_file.exists():
                top_df = pd.read_csv(top_file)
                
                report_content += "### å‰ 10 å€‹æœ€ä½³å€™é¸åˆ†å­\n\n"
                report_content += "| æ’å | åŒ–åˆç‰©åç¨± | çµåˆèƒ½ (kcal/mol) | åˆ†å­é‡ | LogP | QED |\n"
                report_content += "|------|------------|-------------------|--------|------|-----|\n"
                
                for i, row in top_df.head(10).iterrows():
                    report_content += f"| {i+1} | {row['ligand_name']} | {row['binding_affinity']:.2f} | {row['molecular_weight']:.1f} | {row['logp']:.2f} | {row['qed']:.3f} |\n"
                
                report_content += "\n"
        except Exception as e:
            logger.warning(f"âš ï¸ ç„¡æ³•è¼‰å…¥å‰ 10 å€™é¸åˆ†å­: {e}")
        
        # æ·»åŠ åœ–è¡¨éƒ¨åˆ†
        report_content += """## åˆ†æåœ–è¡¨

### çµåˆèƒ½åˆ†ä½ˆ
![çµåˆèƒ½åˆ†ä½ˆ](../figures/binding_affinity_distribution.png)

### ç´¯ç©åˆ†ä½ˆ
![ç´¯ç©åˆ†ä½ˆ](../figures/binding_affinity_cumulative.png)

### æ’åèˆ‡çµåˆèƒ½é—œä¿‚
![æ’å vs çµåˆèƒ½](../figures/rank_vs_affinity.png)

## çµè«–èˆ‡å»ºè­°

### ä¸»è¦ç™¼ç¾
1. æˆåŠŸå®Œæˆå¤§è¦æ¨¡è™›æ“¬ç¯©é¸ï¼Œè­˜åˆ¥å‡ºé«˜è¦ªå’ŒåŠ›å€™é¸åŒ–åˆç‰©
2. é™½æ€§å°ç…§åœ¨çµæœä¸­æ’ååˆç†ï¼Œé©—è­‰äº†ç¯©é¸æ–¹æ³•çš„æœ‰æ•ˆæ€§
3. é€šéå¤šç¶­åº¦ç¯©é¸ç²å¾—äº†å…·æœ‰è‰¯å¥½æˆè—¥æ€§çš„å€™é¸åˆ†å­

### ä¸‹ä¸€æ­¥å»ºè­°
1. **åˆ†å­å‹•åŠ›å­¸é©—è­‰**: å°å‰ 20 å€‹å€™é¸åˆ†å­é€²è¡Œ MD æ¨¡æ“¬é©—è­‰çµåˆç©©å®šæ€§
2. **å¯¦é©—é©—è­‰**: è³¼è²·æˆ–åˆæˆå‰ 5-10 å€‹å€™é¸åˆ†å­é€²è¡Œé«”å¤–æ´»æ€§æ¸¬è©¦
3. **çµæ§‹å„ªåŒ–**: åŸºæ–¼å°æ¥çµæœé€²è¡ŒåŒ–å­¸ä¿®é£¾ä»¥æé«˜è¦ªå’ŒåŠ›å’Œé¸æ“‡æ€§
4. **ADMET é æ¸¬**: é€²è¡Œæ›´è©³ç´°çš„å¸æ”¶ã€åˆ†ä½ˆã€ä»£è¬ã€æ’æ³„å’Œæ¯’æ€§é æ¸¬

---

*æœ¬å ±å‘Šç”± CPV è™›æ“¬ç¯©é¸è‡ªå‹•åŒ–æµç¨‹ç”Ÿæˆ*
"""
        
        # ä¿å­˜å ±å‘Š
        report_file = self.report_dir / "virtual_screening_report.md"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        logger.info(f"ğŸ“„ Markdown å ±å‘Šå·²ä¿å­˜è‡³: {report_file}")
    
    def generate_summary_plots(self):
        """ç”Ÿæˆå ±å‘Šæ‘˜è¦åœ–è¡¨"""
        logger.info("ğŸ“Š ç”Ÿæˆæ‘˜è¦åœ–è¡¨")
        
        plt.style.use('seaborn-v0_8')
        
        # å‰µå»ºå¤šå­åœ–
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        
        try:
            # è¼‰å…¥æ•¸æ“š
            results_file = Path("analysis/binding_affinity/results_with_statistics.csv")
            if results_file.exists():
                df = pd.read_csv(results_file)
                
                # å­åœ– 1: çµåˆèƒ½åˆ†ä½ˆ
                axes[0, 0].hist(df["binding_affinity"], bins=50, alpha=0.7, edgecolor='black')
                axes[0, 0].set_xlabel("Binding Affinity (kcal/mol)")
                axes[0, 0].set_ylabel("Frequency")
                axes[0, 0].set_title("Binding Affinity Distribution")
                
                # å­åœ– 2: å‰ 1000 åæ’ååœ–
                top_1000 = df.head(1000)
                axes[0, 1].scatter(range(1, len(top_1000)+1), top_1000["binding_affinity"], 
                                 alpha=0.6, s=10)
                axes[0, 1].set_xlabel("Rank")
                axes[0, 1].set_ylabel("Binding Affinity (kcal/mol)")
                axes[0, 1].set_title("Top 1000 Compounds")
                
                # å­åœ– 3: Z-score åˆ†ä½ˆ
                if "z_score" in df.columns:
                    axes[1, 0].hist(df["z_score"], bins=50, alpha=0.7, edgecolor='black')
                    axes[1, 0].axvline(-2, color='red', linestyle='--', label='Threshold')
                    axes[1, 0].set_xlabel("Z-Score")
                    axes[1, 0].set_ylabel("Frequency")
                    axes[1, 0].set_title("Z-Score Distribution")
                    axes[1, 0].legend()
                
                # å­åœ– 4: ç¯©é¸æ¼æ–—åœ–
                try:
                    filter_file = Path("analysis/sar/filtering_summary.json")
                    if filter_file.exists():
                        with open(filter_file, 'r') as f:
                            filter_data = json.load(f)
                        
                        stages = ['Original', 'Final Filtered']
                        counts = [filter_data.get('original_results', 0), 
                                filter_data.get('final_filtered', 0)]
                        
                        axes[1, 1].bar(stages, counts, alpha=0.7)
                        axes[1, 1].set_ylabel("Number of Compounds")
                        axes[1, 1].set_title("Filtering Pipeline")
                        
                        # æ·»åŠ æ•¸å€¼æ¨™ç±¤
                        for i, count in enumerate(counts):
                            axes[1, 1].text(i, count + max(counts)*0.01, f'{count:,}', 
                                           ha='center', va='bottom')
                except Exception:
                    pass
            
        except Exception as e:
            logger.warning(f"âš ï¸ ç”Ÿæˆåœ–è¡¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        
        plt.tight_layout()
        summary_plot_file = self.report_dir / "summary_plots.png"
        plt.savefig(summary_plot_file, dpi=300, bbox_inches='tight')
        plt.close()
        
        logger.info(f"ğŸ“Š æ‘˜è¦åœ–è¡¨å·²ä¿å­˜è‡³: {summary_plot_file}")
    
    def generate_full_report(self):
        """ç”Ÿæˆå®Œæ•´å ±å‘Š"""
        logger.info("ğŸš€ ç”Ÿæˆå®Œæ•´åˆ†æå ±å‘Š")
        
        try:
            # ç”Ÿæˆæ‘˜è¦åœ–è¡¨
            self.generate_summary_plots()
            
            # ç”Ÿæˆ Markdown å ±å‘Š
            self.generate_markdown_report()
            
            logger.info("ğŸ‰ å ±å‘Šç”Ÿæˆå®Œæˆï¼")
            logger.info(f"ğŸ“ å ±å‘Šä½ç½®: {self.report_dir}")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ å ±å‘Šç”Ÿæˆå¤±æ•—: {e}")
            return False

if __name__ == "__main__":
    generator = ReportGenerator()
    success = generator.generate_full_report()
    
    if success:
        print("âœ… å ±å‘Šç”Ÿæˆå®Œæˆ")
    else:
        print("âŒ å ±å‘Šç”Ÿæˆå¤±æ•—")